{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cadfbd47",
   "metadata": {},
   "source": [
    "# Loops\n",
    "\n",
    "Loops are used to repeat a process over and over until a given condition is met. It is similar to our process of, for example, searching for a specific quote in a text.\n",
    "\n",
    "Read sentence, \"Is this the sentence I'm looking for?\" you asking yourself, \"No\" your brain affirms-- and so you repeat this process of reading each sentence until you find the one you're looking for. Translating this process into computer, it would look something like this:\n",
    "\n",
    "```\n",
    "for every sentence on this page:\n",
    "    if this is the quote I am looking for:\n",
    "        I can stop reading, I've found it!\n",
    "    if this isn't the quote:\n",
    "        Let's read the next sentence.\n",
    "```\n",
    "\n",
    "In DH applications, for loops allow you to search a large amount of data very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d592078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Atherton\n",
      "Marian Hyde\n",
      "Sybil Dickenson\n",
      "Sabina Dobson\n",
      "Jessica Bradbury\n",
      "Cindy Salter\n",
      "Carolina McCabe\n",
      "Glynis Graves\n",
      "Laurie Dobson\n",
      "Phoebe Watkins\n",
      "Noel Boardman\n"
     ]
    }
   ],
   "source": [
    "# here is a list of names\n",
    "list_of_names = [\"George Atherton\",\n",
    "                \"Marian Hyde\",\n",
    "                \"Sybil Dickenson\",\n",
    "                \"Sabina Dobson\",\n",
    "                \"Jessica Bradbury\",\n",
    "                \"Cindy Salter\",\n",
    "                \"Carolina McCabe\",\n",
    "                \"Glynis Graves\",\n",
    "                \"Laurie Dobson\",\n",
    "                \"Phoebe Watkins\",\n",
    "                \"Noel Boardman\"]\n",
    "\n",
    "# first, we can make a loop to \"iterate\" over the list with no conditions\n",
    "# it will simply continue to go over each item in the list until there is nothing left\n",
    "# to simply just print out every name in the list:\n",
    "\n",
    "for name in list_of_names:\n",
    "    print(name)\n",
    "\n",
    "# NOTE: \"name\" is a variable declared only in the loop, and it stores the item that the loop is presently looking at\n",
    "# in our case, in the first loop \"name\" = \"George Atherton\", and then after that name is printed, the loop repeats and \"name\" = \"Marian Hyde\", in the next loop \"name\" = \"Sybil Dickenson\", and so on until the end of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47484b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sabina Dobson', 'Laurie Dobson']\n"
     ]
    }
   ],
   "source": [
    "# now, like stated earlier, you'll more likely want to use a loop to find something relevant to your work\n",
    "# let's say we're only interested in people with the surname \"Dobson\"\n",
    "# we can use a combination of for loops and if statements to create a new list of only Dobsons!\n",
    "\n",
    "# declare your new list that we will add to\n",
    "only_dobsons = []\n",
    "\n",
    "for name in list_of_names:\n",
    "    # we check if this name includes \"Dobson\"\n",
    "    if \"Dobson\" in name:\n",
    "        # if this is True, we add this name to our new list\n",
    "        only_dobsons.append(name)\n",
    "\n",
    "print(only_dobsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1126966c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Arthur, the greatest of Britain's kings, holds the Christmas festival at Camelot. If he astounded them at first, much more so did he after this speech, and fear held them all silent. They take away his helmet, sword, and shield, and many a proud one presses forward to do him honour. \""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also combine the power of loops with the power of concatenation!\n",
    "# this can be helpful formatting when you have a list of content or multiple files that you would like to perform a large-scale text analysis on (hint hint)\n",
    "\n",
    "# for example, let's put those bits of Arthurian legend we saw in python-I-notebook back together again\n",
    "list_of_sentences = [\"Arthur, the greatest of Britain's kings, holds the Christmas festival at Camelot.\", \n",
    "                     \"If he astounded them at first, much more so did he after this speech, and fear held them all silent.\",\n",
    "                    \"They take away his helmet, sword, and shield, and many a proud one presses forward to do him honour.\"]\n",
    "\n",
    "restored_text = \"\"\n",
    "\n",
    "for sentence in list_of_sentences:\n",
    "    # we update the string with the current content of the string, plus the new content (\"sentence\")\n",
    "    # restored_text = restored_text + sentence + \" \"\n",
    "\n",
    "    # this is more commonly reduced to...\n",
    "    restored_text += sentence + \" \"\n",
    "\n",
    "restored_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f2476",
   "metadata": {},
   "source": [
    "## Practice Activity #4: Loop and Look ðŸ‘€\n",
    "Here is a list of quotes from the novel *Little Women* by Louisa May Alcott. In this activity, use a `for` loop and `if` statement as done above to find quotes that include the word **\"work\"**. These quotes should be added to a new list, then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f526ac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"...I do think washing dishes and keeping things tidy is the worst work in the world. It makes me cross; and my hands get so stiff, I can't practise well at all.\", \"But it does seem so nice to have little suppers and bouquets, and go to parties, and drive home, and read and rest, and not work. It's like other people, you know, and I always envy girls who do such things; I'm so fond of luxury\", 'You may try your experiment for a week, and see how you like it. I think by Saturday night you will find that all play and no work is as bad as all work and no play.']\n"
     ]
    }
   ],
   "source": [
    "little_women_quotes = [\n",
    "                        \"...I do think washing dishes and keeping things tidy is the worst work in the world. It makes me cross; and my hands get so stiff, I can't practise well at all.\",\n",
    "                        \"I don't see how you can write and act such splendid things, Jo. You're a regular Shakespeare!\",\n",
    "                        \"But it does seem so nice to have little suppers and bouquets, and go to parties, and drive home, and read and rest, and not work. It's like other people, you know, and I always envy girls who do such things; I'm so fond of luxury\",\n",
    "                        \"She caught up her knitting, which had dropped out of her hands, gave me a sharp look through her specs, and said, in her short way, 'Finish the chapter, and don't be impertinent, miss.'\",\n",
    "                        \"You may try your experiment for a week, and see how you like it. I think by Saturday night you will find that all play and no work is as bad as all work and no play.\"\n",
    "                    ]\n",
    "    \n",
    "new_list = []\n",
    "\n",
    "for quote in little_women_quotes:\n",
    "    if \"work\" in quote:\n",
    "        new_list.append(quote)\n",
    "\n",
    "print(new_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec82c34a",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "'Functions' are blocks of reuseable code; as you know by now, in Python there are many functions such as `print()` or `len()` which were designed to perform specific tasks when called. If in your own code you believe that there is a task you will need to repeat multiple times at various points, you can write a function yourself! For example, instead of having something like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12664f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cindy Salter's age: 30\n",
      "Glynis Graves's age: 78\n",
      "Noel Boardman's age: 64\n"
     ]
    }
   ],
   "source": [
    "# find age of each person from records\n",
    "life_records = [\n",
    "                [\"Cindy Salter\", \"Born: 1903\", \"Died: 1933\"], \n",
    "                [\"Glynis Graves\", \"Born: 1911\", \"Died: 1989\"], \n",
    "                [\"Noel Boardman\", \"Born: 1908\", \"Died: 1972\"]\n",
    "                ]\n",
    "\n",
    "cs_born = life_records[0][1]\n",
    "cs_death = life_records[0][2]\n",
    "\n",
    "# get only the number\n",
    "for word in cs_born.split():\n",
    "    if word.isdigit():\n",
    "        cs_born = int(word)\n",
    "\n",
    "for word in cs_death.split():\n",
    "    if word.isdigit():\n",
    "        cs_death = int(word)\n",
    "\n",
    "cs_age = cs_death - cs_born\n",
    "print(life_records[0][0] + \"'s age: \" + str(cs_age))\n",
    "\n",
    "gg_born = life_records[1][1]\n",
    "gg_death = life_records[1][2]\n",
    "\n",
    "# get only the number\n",
    "for word in gg_born.split():\n",
    "    if word.isdigit():\n",
    "        gg_born = int(word)\n",
    "\n",
    "for word in gg_death.split():\n",
    "    if word.isdigit():\n",
    "        gg_death = int(word)\n",
    "\n",
    "gg_age = gg_death - gg_born\n",
    "print(life_records[1][0] + \"'s age: \" + str(gg_age))\n",
    "\n",
    "nb_born = life_records[2][1]\n",
    "nb_death = life_records[2][2]\n",
    "\n",
    "# get only the number\n",
    "for word in nb_born.split():\n",
    "    if word.isdigit():\n",
    "        nb_born = int(word)\n",
    "\n",
    "for word in nb_death.split():\n",
    "    if word.isdigit():\n",
    "        nb_death = int(word)\n",
    "\n",
    "nb_age = nb_death - nb_born\n",
    "print(life_records[2][0] + \"'s age: \" + str(nb_age))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49a6d748",
   "metadata": {},
   "source": [
    "...We could have something much tidier and easier to read, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1ed90e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cindy Salter's age: 30\n",
      "Glynis Graves's age: 78\n",
      "Noel Boardman's age: 64\n"
     ]
    }
   ],
   "source": [
    "# find age of each person from records\n",
    "life_records = [\n",
    "                [\"Cindy Salter\", \"Born: 1903\", \"Died: 1933\"], \n",
    "                [\"Glynis Graves\", \"Born: 1911\", \"Died: 1989\"], \n",
    "                [\"Noel Boardman\", \"Born: 1908\", \"Died: 1972\"]\n",
    "                ]\n",
    "\n",
    "def find_age(record):\n",
    "    born = ''\n",
    "    death = ''\n",
    "    for word in record[1].split():\n",
    "        if word.isdigit():\n",
    "            born = int(word)\n",
    "\n",
    "    for word in record[2].split():\n",
    "        if word.isdigit():\n",
    "            death = int(word)\n",
    "\n",
    "    age = record[0] + \"'s age: \" + str(death - born)\n",
    "    return age\n",
    "\n",
    "print(find_age(life_records[0]))\n",
    "print(find_age(life_records[1]))\n",
    "print(find_age(life_records[2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa67a40d",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "Now, what can make your code even *tidier*, plus easier to read *and* write? Libraries! Also referred to as \"packages\", these helpful tools are essentially large collections of pre-written functions that you can install in your Python environment and import so that you can use these functions in your code. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce45a0a0",
   "metadata": {},
   "source": [
    "## NLTK (Natural Language Tool Kit)\n",
    "\n",
    "In this workshop, we will be introducing two libraries which are necessities for any digital humanist's tool kit the first of which is [NLTK (Natural Language Tool Kit)](https://www.nltk.org/). This is an all-encompassing library to support work in natural language processing (NLP), a multidisciplinary field which deals with the interactions between \"natural\" human language and computers. It has its roots in linguisitics which is why it can do things like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fbce7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in /home/iris_luc/Apps/miniconda3/lib/python3.13/site-packages (from nltk) (8.1.8)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.11.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /home/iris_luc/Apps/miniconda3/lib/python3.13/site-packages (from nltk) (4.67.1)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [nltk][32m2/3\u001b[0m [nltk]b]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 nltk-3.9.2 regex-2025.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665c9ba",
   "metadata": {},
   "source": [
    "# IMPORTANT CHANGE!\n",
    "\n",
    "punkt --> punkt_tab\n",
    "\n",
    "averaged_perceptron_tagger --> averaged_perceptron_tagger_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75f3625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/iris_luc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/iris_luc/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Be', 'VB'),\n",
       " ('careful', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('butter', 'NN'),\n",
       " ('knife', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# tagging PoS in inputted text\n",
    "text = word_tokenize(\"Be careful with that butter knife.\")\n",
    "nltk.pos_tag(text)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f97b55f",
   "metadata": {},
   "source": [
    "...But as the `word_tokenize()` function hints at, NLTK is also excellent at preparing text for and performing textual analysis in a less particulated manner!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1c14330",
   "metadata": {},
   "source": [
    "(**Note**: NLTK uses the Penn Treebank Tag Set for POS tagging, [which can be found here](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90ab267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/iris_luc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/iris_luc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Bette-Smith-Transcript.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33mstopwords\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# to import a .txt file we use the \"open\" function, giving it the path to our text file and an instrution about what we want to do with the file\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# here, we would like to \"read\" our file into a variable so \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m transcript = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBette-Smith-Transcript.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.read().lower()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/miniconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Bette-Smith-Transcript.txt'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# tokenization is the process of splitting strings into their individual \"tokens\"\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# to import a .txt file we use the \"open\" function, giving it the path to our text file and an instrution about what we want to do with the file\n",
    "# here, we would like to \"read\" our file into a variable so \n",
    "transcript = open('Bette-Smith-Transcript.txt').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a34d549",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# we could then tokenize by sentence, which splits the text into sentences\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m transcript_sentences = \u001b[43msent_tokenize\u001b[49m(transcript)\n\u001b[32m      3\u001b[39m transcript_sentences\n",
      "\u001b[31mNameError\u001b[39m: name 'sent_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "# we could then tokenize by sentence, which splits the text into sentences\n",
    "transcript_sentences = sent_tokenize(transcript)\n",
    "transcript_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a14bee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transcript' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# or more commonly, we can tokenize into words, which splits the sentences into its parts of speech\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m transcript_words = word_tokenize(\u001b[43mtranscript\u001b[49m)\n\u001b[32m      3\u001b[39m transcript_words\n",
      "\u001b[31mNameError\u001b[39m: name 'transcript' is not defined"
     ]
    }
   ],
   "source": [
    "# or more commonly, we can tokenize into words, which splits the sentences into its parts of speech\n",
    "transcript_words = word_tokenize(transcript)\n",
    "transcript_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bb6ab32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'bette',\n",
       " 'smith',\n",
       " ',',\n",
       " 'grew',\n",
       " 'ottawa',\n",
       " 'carleton',\n",
       " ',',\n",
       " 'carling',\n",
       " 'area',\n",
       " ',',\n",
       " 'sorry',\n",
       " \"'m\",\n",
       " 'going',\n",
       " 'back',\n",
       " 'little',\n",
       " 'bit',\n",
       " '.',\n",
       " 'went',\n",
       " 'fisher',\n",
       " 'park',\n",
       " 'high',\n",
       " 'school',\n",
       " ',',\n",
       " ',',\n",
       " 'went',\n",
       " 'grade',\n",
       " '13',\n",
       " ',',\n",
       " 'usually',\n",
       " 'prepares',\n",
       " 'university',\n",
       " '.',\n",
       " 'however',\n",
       " ',',\n",
       " 'grade',\n",
       " '13',\n",
       " 'year',\n",
       " ',',\n",
       " 'really',\n",
       " \"n't\",\n",
       " 'feel',\n",
       " 'wanted',\n",
       " 'go',\n",
       " 'university',\n",
       " ',',\n",
       " 'decided',\n",
       " 'instead',\n",
       " 'take',\n",
       " 'money',\n",
       " 'parents',\n",
       " 'put',\n",
       " 'aside',\n",
       " 'schooling',\n",
       " 'whatever',\n",
       " 'went',\n",
       " 'business',\n",
       " 'college',\n",
       " 'instead',\n",
       " '.',\n",
       " 'took',\n",
       " 'year',\n",
       " 'willis',\n",
       " 'business',\n",
       " 'college',\n",
       " 'downtown',\n",
       " 'ottawa',\n",
       " ',',\n",
       " 'end',\n",
       " ',',\n",
       " 'said',\n",
       " 'well',\n",
       " ',',\n",
       " 'would',\n",
       " 'like',\n",
       " 'work',\n",
       " '?',\n",
       " 'said',\n",
       " 'maybe',\n",
       " 'would',\n",
       " 'like',\n",
       " 'work',\n",
       " 'university',\n",
       " '.',\n",
       " 'actually',\n",
       " 'got',\n",
       " 'job',\n",
       " ',',\n",
       " \"n't\",\n",
       " 'apply',\n",
       " '.',\n",
       " 'started',\n",
       " 'carleton',\n",
       " 'university',\n",
       " '1972',\n",
       " ',',\n",
       " 'would',\n",
       " '19',\n",
       " 'years',\n",
       " 'age',\n",
       " '.',\n",
       " 'started',\n",
       " 'steno',\n",
       " '03',\n",
       " ',',\n",
       " 'basically',\n",
       " 'bottom',\n",
       " 'pile',\n",
       " ',',\n",
       " 'remember',\n",
       " 'made',\n",
       " '3,500',\n",
       " 'year',\n",
       " '.',\n",
       " 'point',\n",
       " \"n't\",\n",
       " 'enough',\n",
       " 'live',\n",
       " ',',\n",
       " 'even',\n",
       " 'dollar',\n",
       " 'days',\n",
       " '.',\n",
       " 'live',\n",
       " 'home',\n",
       " 'another',\n",
       " 'couple',\n",
       " 'years',\n",
       " '.',\n",
       " 'basically',\n",
       " 'started',\n",
       " 'steno',\n",
       " '03',\n",
       " ',',\n",
       " 'rose',\n",
       " 'bit',\n",
       " 'ranks',\n",
       " '.',\n",
       " ',',\n",
       " 'years',\n",
       " 'carleton',\n",
       " 'formative',\n",
       " 'terms',\n",
       " 'going',\n",
       " ',',\n",
       " 'towards',\n",
       " 'administration',\n",
       " '.',\n",
       " 'yeah',\n",
       " '.',\n",
       " 'little',\n",
       " ',',\n",
       " 'terms',\n",
       " 'family',\n",
       " '.',\n",
       " 'siblings',\n",
       " '?',\n",
       " 'four',\n",
       " 'sisters',\n",
       " 'two',\n",
       " 'brothers',\n",
       " '.',\n",
       " \"'m\",\n",
       " 'one',\n",
       " '7.',\n",
       " 'pecking',\n",
       " 'order',\n",
       " 'would',\n",
       " '2nd',\n",
       " 'youngest',\n",
       " ',',\n",
       " 'family',\n",
       " ',',\n",
       " \"'re\",\n",
       " 'looking',\n",
       " 'class',\n",
       " ',',\n",
       " 'know',\n",
       " 'interest',\n",
       " 'particular',\n",
       " 'thesis',\n",
       " 'study',\n",
       " ',',\n",
       " 'mother',\n",
       " 'middle',\n",
       " 'class',\n",
       " '.',\n",
       " 'dad',\n",
       " 'would',\n",
       " 'farm',\n",
       " 'family',\n",
       " '.',\n",
       " 'remember',\n",
       " 'sort',\n",
       " 'going',\n",
       " 'finances',\n",
       " 'one',\n",
       " 'time',\n",
       " 'quite',\n",
       " 'proud',\n",
       " 'tell',\n",
       " 'felt',\n",
       " 'achieved',\n",
       " 'middle',\n",
       " 'class',\n",
       " '.',\n",
       " 'although',\n",
       " 'lower',\n",
       " 'middle',\n",
       " 'class',\n",
       " ',',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'nonetheless',\n",
       " '.',\n",
       " 'terms',\n",
       " 'siblings',\n",
       " ',',\n",
       " 'eldest',\n",
       " 'went',\n",
       " 'accounts',\n",
       " 'payable',\n",
       " ',',\n",
       " 'accounts',\n",
       " 'receivable',\n",
       " 'work',\n",
       " '.',\n",
       " 'brother',\n",
       " 'gordon',\n",
       " 'went',\n",
       " 'master',\n",
       " \"'s\",\n",
       " 'social',\n",
       " 'work',\n",
       " ',',\n",
       " 'sorry',\n",
       " 'social',\n",
       " 'work',\n",
       " ',',\n",
       " 'sociology',\n",
       " 'actually',\n",
       " 'doctoral',\n",
       " 'work',\n",
       " 'london',\n",
       " 'school',\n",
       " 'economics',\n",
       " '.',\n",
       " 'margaret',\n",
       " 'went',\n",
       " 'secretary',\n",
       " 'law',\n",
       " 'firm',\n",
       " '.',\n",
       " 'pat',\n",
       " 'went',\n",
       " 'master',\n",
       " \"'s\",\n",
       " 'library',\n",
       " 'science',\n",
       " 'well',\n",
       " 'degree',\n",
       " 'journalism',\n",
       " '.',\n",
       " 'dj',\n",
       " 'course',\n",
       " 'also',\n",
       " 'done',\n",
       " 'graduate',\n",
       " 'work',\n",
       " 'political',\n",
       " 'science',\n",
       " ',',\n",
       " 'actually',\n",
       " 'well',\n",
       " 'history',\n",
       " '.',\n",
       " 'edward',\n",
       " 'done',\n",
       " 'writing',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'real',\n",
       " 'mix',\n",
       " 'bag',\n",
       " 'terms',\n",
       " 'whether',\n",
       " \"'ve\",\n",
       " 'gone',\n",
       " 'university',\n",
       " 'studies',\n",
       " 'whether',\n",
       " \"'ve\",\n",
       " 'gone',\n",
       " 'might',\n",
       " 'call',\n",
       " 'support',\n",
       " 'roles',\n",
       " '.',\n",
       " 'actually',\n",
       " 'bachelor',\n",
       " \"'s\",\n",
       " 'degree',\n",
       " 'english',\n",
       " 'lit',\n",
       " ',',\n",
       " 'put',\n",
       " 'good',\n",
       " 'use',\n",
       " 'correcting',\n",
       " 'everybody',\n",
       " \"'s\",\n",
       " 'grammar',\n",
       " 'could',\n",
       " 'possibly',\n",
       " 'correct',\n",
       " '.',\n",
       " 'ba',\n",
       " 'english',\n",
       " 'lit',\n",
       " '?',\n",
       " 'started',\n",
       " 'couple',\n",
       " 'courses',\n",
       " 'carleton',\n",
       " 'one',\n",
       " 'perks',\n",
       " 'staff',\n",
       " 'get',\n",
       " 'free',\n",
       " 'courses',\n",
       " '.',\n",
       " 'certainly',\n",
       " 'took',\n",
       " 'advantage',\n",
       " '.',\n",
       " 'took',\n",
       " 'two',\n",
       " 'courses',\n",
       " 'believe',\n",
       " 'carleton',\n",
       " '.',\n",
       " 'one',\n",
       " 'classics',\n",
       " 'one',\n",
       " 'sociology',\n",
       " '.',\n",
       " 'transferred',\n",
       " 'laurier',\n",
       " 'university',\n",
       " 'finished',\n",
       " 'degree',\n",
       " ',',\n",
       " 'eventually',\n",
       " 'ended',\n",
       " 'working',\n",
       " 'laurier',\n",
       " '.',\n",
       " 'finish',\n",
       " 'degree',\n",
       " 'laurier',\n",
       " '?',\n",
       " 'took',\n",
       " '13',\n",
       " 'years',\n",
       " '.',\n",
       " 'finished',\n",
       " '1986',\n",
       " 'part',\n",
       " 'time',\n",
       " 'student',\n",
       " '.',\n",
       " 'think',\n",
       " 'one',\n",
       " 'year',\n",
       " 'actually',\n",
       " '3',\n",
       " 'courses',\n",
       " 'term',\n",
       " '.',\n",
       " 'insane',\n",
       " '.',\n",
       " 'yeah',\n",
       " \"'s\",\n",
       " 'hard',\n",
       " ',',\n",
       " 'know',\n",
       " ',',\n",
       " 'work',\n",
       " ',',\n",
       " 'work',\n",
       " 'full',\n",
       " 'time',\n",
       " 'courses',\n",
       " '.',\n",
       " 'family',\n",
       " ',',\n",
       " 'know',\n",
       " '.',\n",
       " 'luckily',\n",
       " ',',\n",
       " 'know',\n",
       " ',',\n",
       " 'single',\n",
       " ',',\n",
       " '.',\n",
       " 'say',\n",
       " 'mom',\n",
       " 'middle',\n",
       " 'class',\n",
       " ',',\n",
       " 'mean',\n",
       " '?',\n",
       " 'well',\n",
       " 'grew',\n",
       " 'village',\n",
       " 'cumberland',\n",
       " ',',\n",
       " 'family',\n",
       " 'dad',\n",
       " 'postmaster',\n",
       " 'well',\n",
       " 'owned',\n",
       " 'store',\n",
       " 'village',\n",
       " '.',\n",
       " 'moved',\n",
       " 'ottawa',\n",
       " ',',\n",
       " 'mean',\n",
       " 'lived',\n",
       " 'really',\n",
       " 'fine',\n",
       " 'home',\n",
       " 'cook',\n",
       " ',',\n",
       " 'sold',\n",
       " 'insurance',\n",
       " 'fact',\n",
       " 'top',\n",
       " 'salesman',\n",
       " 'one',\n",
       " 'big',\n",
       " 'companies',\n",
       " '.',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'great',\n",
       " 'deal',\n",
       " 'money',\n",
       " ',',\n",
       " 'lived',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'lifestyle',\n",
       " '.',\n",
       " 'cook',\n",
       " ',',\n",
       " 'somebody',\n",
       " 'would',\n",
       " 'come',\n",
       " 'clean',\n",
       " ',',\n",
       " 'mother',\n",
       " 'never',\n",
       " 'learned',\n",
       " 'cook',\n",
       " 'egg',\n",
       " 'got',\n",
       " 'married',\n",
       " \"n't\",\n",
       " 'allowed',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'dad',\n",
       " 'cook',\n",
       " '.',\n",
       " 'say',\n",
       " 'farm',\n",
       " 'family',\n",
       " ',',\n",
       " 'area',\n",
       " '?',\n",
       " 'little',\n",
       " 'farm',\n",
       " 'basically',\n",
       " 'cumberland',\n",
       " 'rockland',\n",
       " '.',\n",
       " 'fact',\n",
       " ',',\n",
       " \"'re\",\n",
       " 'going',\n",
       " 'cumberland',\n",
       " 'tomorrow',\n",
       " 'memorial',\n",
       " 'service',\n",
       " '.',\n",
       " 'see',\n",
       " 'friends',\n",
       " 'relatives',\n",
       " '.',\n",
       " ',',\n",
       " ',',\n",
       " 'work',\n",
       " 'farm',\n",
       " '?',\n",
       " 'dad',\n",
       " 'never',\n",
       " 'really',\n",
       " ',',\n",
       " 'loved',\n",
       " 'gardening',\n",
       " 'friends',\n",
       " 'animals',\n",
       " '.',\n",
       " 'would',\n",
       " ',',\n",
       " 'apparently',\n",
       " ',',\n",
       " 'growing',\n",
       " ',',\n",
       " 'understand',\n",
       " 'born',\n",
       " '1908',\n",
       " ',',\n",
       " 'draft',\n",
       " 'horses',\n",
       " '.',\n",
       " 'apparently',\n",
       " 'never',\n",
       " 'anything',\n",
       " 'dad',\n",
       " 'would',\n",
       " 'tell',\n",
       " '.',\n",
       " 'much',\n",
       " 'home',\n",
       " 'machinery',\n",
       " '.',\n",
       " 'loved',\n",
       " 'tinkering',\n",
       " 'machinery',\n",
       " '.',\n",
       " 'also',\n",
       " 'enjoyed',\n",
       " 'work',\n",
       " 'later',\n",
       " 'city',\n",
       " 'ottawa',\n",
       " 'filtration',\n",
       " 'plant',\n",
       " '.',\n",
       " 'worked',\n",
       " 'machinery',\n",
       " 'well',\n",
       " 'chemical',\n",
       " 'tests',\n",
       " 'forth',\n",
       " '.',\n",
       " ',',\n",
       " 'move',\n",
       " 'ottawa',\n",
       " 'got',\n",
       " 'married',\n",
       " ',',\n",
       " '?',\n",
       " 'yes',\n",
       " '.',\n",
       " 'actually',\n",
       " 'first',\n",
       " 'job',\n",
       " 'ottawa',\n",
       " ',',\n",
       " 'got',\n",
       " 'married',\n",
       " ',',\n",
       " 'running',\n",
       " 'elevator',\n",
       " 'one',\n",
       " 'stores',\n",
       " 'downtown',\n",
       " ',',\n",
       " 'ogilvieï¿½s',\n",
       " 'forth',\n",
       " ',',\n",
       " 'still',\n",
       " 'let',\n",
       " 'people',\n",
       " 'go',\n",
       " '.',\n",
       " 'mom',\n",
       " 'would',\n",
       " 'come',\n",
       " 'little',\n",
       " 'bag',\n",
       " 'lunch',\n",
       " ',',\n",
       " 'would',\n",
       " 'ride',\n",
       " 'elevator',\n",
       " 'together',\n",
       " ',',\n",
       " 'thought',\n",
       " 'romantic',\n",
       " '.',\n",
       " 'yeah',\n",
       " ',',\n",
       " 'absolutely',\n",
       " '.',\n",
       " 'point',\n",
       " 'started',\n",
       " 'work',\n",
       " 'city',\n",
       " '?',\n",
       " 'yes',\n",
       " ',',\n",
       " 'think',\n",
       " 'brother',\n",
       " 'law',\n",
       " 'got',\n",
       " 'job',\n",
       " ',',\n",
       " 'first',\n",
       " 'war',\n",
       " 'guard',\n",
       " 'filtration',\n",
       " 'plant',\n",
       " '.',\n",
       " 'kind',\n",
       " 'lunatic',\n",
       " 'job',\n",
       " \"n't\",\n",
       " 'give',\n",
       " 'bullets',\n",
       " 'guns',\n",
       " '.',\n",
       " 'made',\n",
       " 'stand',\n",
       " 'outside',\n",
       " 'building',\n",
       " 'lights',\n",
       " 'guards',\n",
       " '.',\n",
       " 'know',\n",
       " ',',\n",
       " 'could',\n",
       " 'picked',\n",
       " 'course',\n",
       " 'anybody',\n",
       " 'fired',\n",
       " ',',\n",
       " 'run',\n",
       " 'back',\n",
       " 'building',\n",
       " 'get',\n",
       " 'bullets',\n",
       " 'come',\n",
       " 'back',\n",
       " '.',\n",
       " \"n't\",\n",
       " 'think',\n",
       " 'taking',\n",
       " 'pretty',\n",
       " 'seriously',\n",
       " '.',\n",
       " 'show',\n",
       " '.',\n",
       " 'yeah',\n",
       " ',',\n",
       " 'war',\n",
       " '?',\n",
       " 'happened',\n",
       " '?',\n",
       " 'whatever',\n",
       " 'reason',\n",
       " ',',\n",
       " 'able',\n",
       " 'get',\n",
       " 'job',\n",
       " 'within',\n",
       " 'plant',\n",
       " ',',\n",
       " 'guess',\n",
       " 'showed',\n",
       " 'facilities',\n",
       " 'chemistry',\n",
       " '.',\n",
       " 'know',\n",
       " ',',\n",
       " 'high',\n",
       " 'school',\n",
       " ',',\n",
       " 'point',\n",
       " 'pretty',\n",
       " 'good',\n",
       " 'time',\n",
       " 'frame',\n",
       " '.',\n",
       " 'actually',\n",
       " 'wanted',\n",
       " 'go',\n",
       " 'university',\n",
       " ',',\n",
       " 'mother',\n",
       " 'pushing',\n",
       " '.',\n",
       " 'died',\n",
       " ',',\n",
       " 'dad',\n",
       " 'said',\n",
       " \"n't\",\n",
       " 'need',\n",
       " '.',\n",
       " 'always',\n",
       " 'behind',\n",
       " 'higher',\n",
       " 'education',\n",
       " '.',\n",
       " 'yeah',\n",
       " '.',\n",
       " 'mom',\n",
       " '?',\n",
       " '?',\n",
       " 'actually',\n",
       " ',',\n",
       " 'went',\n",
       " 'think',\n",
       " 'grade',\n",
       " '9',\n",
       " 'time',\n",
       " 'growing',\n",
       " 'well',\n",
       " '.',\n",
       " 'high',\n",
       " 'school',\n",
       " ',',\n",
       " 'even',\n",
       " ',',\n",
       " 'young',\n",
       " 'ladies',\n",
       " ',',\n",
       " \"n't\",\n",
       " 'necessary',\n",
       " '.',\n",
       " 'actually',\n",
       " 'go',\n",
       " 'back',\n",
       " 'dad',\n",
       " 'passed',\n",
       " 'away',\n",
       " 'finished',\n",
       " 'high',\n",
       " 'school',\n",
       " '.',\n",
       " 'yeah',\n",
       " '.',\n",
       " 'proud',\n",
       " '.',\n",
       " ',',\n",
       " 'growing',\n",
       " ',',\n",
       " 'cook',\n",
       " 'cleaner',\n",
       " 'kind',\n",
       " 'thing',\n",
       " '.',\n",
       " 'growing',\n",
       " ',',\n",
       " 'household',\n",
       " 'like',\n",
       " '?',\n",
       " 'crowded',\n",
       " '.',\n",
       " 'course',\n",
       " '.',\n",
       " ',',\n",
       " 'grandmother',\n",
       " ',',\n",
       " 'mother',\n",
       " \"'s\",\n",
       " 'mother',\n",
       " 'bought',\n",
       " 'house',\n",
       " 'straight',\n",
       " 'mom',\n",
       " 'dad',\n",
       " '.',\n",
       " 'otherwise',\n",
       " 'probably',\n",
       " 'could',\n",
       " 'afforded',\n",
       " '.',\n",
       " 'bought',\n",
       " 'large',\n",
       " 'house',\n",
       " ',',\n",
       " 'beautifully',\n",
       " 'made',\n",
       " ',',\n",
       " 'two',\n",
       " 'large',\n",
       " 'bedrooms',\n",
       " ',',\n",
       " 'one',\n",
       " 'small',\n",
       " 'bedroom',\n",
       " '.',\n",
       " 'parents',\n",
       " 'actually',\n",
       " 'ended',\n",
       " ',',\n",
       " 'fold-up',\n",
       " 'couch',\n",
       " 'downstairs',\n",
       " ',',\n",
       " 'always',\n",
       " 'knew',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'get',\n",
       " 'mom',\n",
       " 'dad',\n",
       " ',',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'walk',\n",
       " 'around',\n",
       " 'night',\n",
       " ',',\n",
       " 'know',\n",
       " '.',\n",
       " \"n't\",\n",
       " 'lot',\n",
       " 'privacy',\n",
       " 'house',\n",
       " ',',\n",
       " 'fun',\n",
       " 'nonetheless',\n",
       " '.',\n",
       " 'course',\n",
       " 'mom',\n",
       " 'work',\n",
       " 'trained',\n",
       " 'early',\n",
       " 'help',\n",
       " '.',\n",
       " ',',\n",
       " 'stay',\n",
       " 'house',\n",
       " 'long',\n",
       " 'time',\n",
       " '?',\n",
       " 'yes',\n",
       " '.',\n",
       " ',',\n",
       " 'think',\n",
       " 'moved',\n",
       " 'brother',\n",
       " 'maybe',\n",
       " '2',\n",
       " '3.',\n",
       " 'fairly',\n",
       " ',',\n",
       " 'know',\n",
       " ',',\n",
       " 'would',\n",
       " '1943',\n",
       " ',',\n",
       " '1945.',\n",
       " 'stayed',\n",
       " 'certainly',\n",
       " 'throughout',\n",
       " 'dad',\n",
       " \"'s\",\n",
       " 'entire',\n",
       " 'married',\n",
       " 'life',\n",
       " '.',\n",
       " 'mother',\n",
       " 'sold',\n",
       " 'maybe',\n",
       " '10',\n",
       " 'years',\n",
       " 'dad',\n",
       " 'died',\n",
       " '.',\n",
       " 'difficult',\n",
       " 'keep',\n",
       " 'expensive',\n",
       " 'pension',\n",
       " '.',\n",
       " 'yeah',\n",
       " ',',\n",
       " 'yeah',\n",
       " '.',\n",
       " 'sort',\n",
       " 'one',\n",
       " 'memory',\n",
       " 'growing',\n",
       " 'kind',\n",
       " 'characteristic',\n",
       " 'family',\n",
       " ',',\n",
       " 'sort',\n",
       " 'showed',\n",
       " 'something',\n",
       " 'family',\n",
       " 'culture',\n",
       " ',',\n",
       " 'would',\n",
       " '?',\n",
       " 'guys',\n",
       " ',',\n",
       " 'special',\n",
       " 'traditions',\n",
       " ',',\n",
       " 'take',\n",
       " 'trips',\n",
       " 'together',\n",
       " ',',\n",
       " '?',\n",
       " 'one',\n",
       " 'trip',\n",
       " 'take',\n",
       " 'together',\n",
       " 'something',\n",
       " 'disaster',\n",
       " '.',\n",
       " 'dad',\n",
       " 'decided',\n",
       " 'wanted',\n",
       " 'show',\n",
       " 'us',\n",
       " 'st.',\n",
       " 'laurence',\n",
       " ',',\n",
       " 'started',\n",
       " ',',\n",
       " 'packed',\n",
       " 'little',\n",
       " 'car',\n",
       " '.',\n",
       " \"n't\",\n",
       " 'really',\n",
       " 'little',\n",
       " 'car',\n",
       " ',',\n",
       " 'oldsmobile',\n",
       " ',',\n",
       " 'know',\n",
       " 'least',\n",
       " '4',\n",
       " 'kids',\n",
       " 'back',\n",
       " 'mom',\n",
       " 'dad',\n",
       " 'front',\n",
       " ',',\n",
       " 'older',\n",
       " 'kids',\n",
       " \"n't\",\n",
       " 'come',\n",
       " '.',\n",
       " 'along',\n",
       " ',',\n",
       " 'got',\n",
       " 'certain',\n",
       " 'place',\n",
       " 'said',\n",
       " ',',\n",
       " '!',\n",
       " \"'s\",\n",
       " 'st.',\n",
       " 'laurence',\n",
       " '!',\n",
       " 'said',\n",
       " ',',\n",
       " ',',\n",
       " '?',\n",
       " 'said',\n",
       " ',',\n",
       " 'way',\n",
       " '!',\n",
       " \"'re\",\n",
       " 'going',\n",
       " 'home',\n",
       " '.',\n",
       " 'okay',\n",
       " '.',\n",
       " 'enough',\n",
       " ',',\n",
       " 'know',\n",
       " 'driving',\n",
       " 'kids',\n",
       " 'carping',\n",
       " 'forth',\n",
       " '.',\n",
       " 'drive',\n",
       " 'lot',\n",
       " '.',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now remember that huge block of stopwords manually typed out in the sample block of code from the first lesson? That comes built in to NLTK as you may have guessed from the earlier import statment\n",
    "# we can assign the NLTK stopwords to a variable like so:\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# and then remove the stopwords from out text using a loop to check if each word in the transcript and only keep the words that are NOT in out stopword list\n",
    "filtered_transcript_words = []\n",
    "for word in transcript_words:\n",
    "    if word not in stop_words:\n",
    "        filtered_transcript_words.append(word)\n",
    "\n",
    "filtered_transcript_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d267049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 885),\n",
       " ('.', 712),\n",
       " ('?', 119),\n",
       " (\"n't\", 111),\n",
       " ('would', 94),\n",
       " (\"'s\", 86),\n",
       " ('know', 73),\n",
       " ('staff', 61),\n",
       " ('faculty', 60),\n",
       " ('think', 58)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally, we can simply find word frequeny with NLTK's frequnecy distribution function\n",
    "from nltk import FreqDist\n",
    "\n",
    "transcript_fdist = FreqDist(filtered_transcript_words)\n",
    "transcript_fdist.most_common(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c89499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, as you can see, our list is topped by punctuation and contractions!\n",
    "\n",
    "# to remove punctuation, we can use Python's string library to create a list of punctuation\n",
    "from string import punctuation\n",
    "punctuation = list(punctuation)\n",
    "\n",
    "# and luckily, you can modify your stopwords and punctuation lists like any other list!\n",
    "# let's add \"n't\", \"'s\", and \"would\"\n",
    "# to add multiple elements to a list at once, we use extend() rather that append()\n",
    "stop_words.extend([\"n't\", \"'s\", 'would'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e041fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('know', 73),\n",
       " ('staff', 61),\n",
       " ('faculty', 60),\n",
       " ('think', 58),\n",
       " ('well', 52),\n",
       " ('work', 52),\n",
       " ('going', 47),\n",
       " ('yeah', 44),\n",
       " ('really', 41),\n",
       " ('like', 39)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's re-run with our new stopwords and punctuation list to see the improved results\n",
    "filtered_transcript_words = []\n",
    "for word in transcript_words:\n",
    "    if word not in stop_words and word not in punctuation:\n",
    "        filtered_transcript_words.append(word)\n",
    "\n",
    "transcript_fdist = FreqDist(filtered_transcript_words)\n",
    "transcript_fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8afdfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 52 of 52 matches:\n",
      "to me well , where would you like to work ? and i said maybe i would like to w\n",
      "k ? and i said maybe i would like to work at the university . so they actually\n",
      "counts payable , accounts receivable work . my brother gordon went on to do a \n",
      " went on to do a master 's in social work , sorry not social work , sociology \n",
      "'s in social work , sorry not social work , sociology and actually did some do\n",
      "ology and actually did some doctoral work at london school of economics . marg\n",
      "n dj of course is also done graduate work in political science , actually as w\n",
      "h it 's very hard , as you know , to work , to work full time and do courses .\n",
      "ry hard , as you know , to work , to work full time and do courses . and have \n",
      "ves . so then did he , when , did he work that farm ? dad was never really , h\n",
      " machinery . and he also enjoyed his work later on with the city of ottawa whi\n",
      "and then he at some point started to work for the city ? yes , i think his bro\n",
      " . and of course mom did most of the work but we were trained early to help . \n",
      "ll destroyed . so there was a lot of work to be done . we had a full insurance\n",
      "r had the time to do that particular work . and depending on who the faculty p\n",
      "terms of what went to the top of the work pile . and can you remember any of t\n",
      "ny spaces across the page you had to work with , and map it basically . but yo\n",
      "t have certain professors could just work with certain stenos . and instead of\n",
      "line , we would sort of divvy up the work . well apparently it started a stamp\n",
      "ut i got her position , so i went to work for the chair of the department way \n",
      "i had an important appointment after work , i want to leave , and he said i 'v\n",
      "ward in terms of getting it into the work flow , that could be a little bit of\n",
      "and i believe he had respect for our work as long as we did our job and did it\n",
      "er her name . she was a total joy to work with . why ? because she had started\n",
      "was very careful in how she prepared work . and it was always that you just di\n",
      ", coffee breaks , lunch , outside of work ? i did with , not really with the t\n",
      "a secretary and to have a family and work . i actually socialized more with el\n",
      " the attitude that you bring to your work . that you do your best , that you u\n",
      "enhance your skills so that what the work is , that you 're making , i 've alw\n",
      "then it needs to be ensured that the work that 's done for the faculty can not\n",
      "ut back accordingly . same amount of work needs to be done by the people who r\n",
      "of the faculty demands that included work done by staff . i do n't know how th\n",
      "uded but faculty had a stake in what work was being done for them in the offic\n",
      "o pick up the slack and still do the work . so if in our area there were 3 ste\n",
      "en the 2 that were left would do the work for all the faculty . it 's not that\n",
      "oint then start taking some of their work elsewhere and if they 're getting gr\n",
      " all the time . lazy . impossible to work with . was n't doing his job properl\n",
      "t really like that part time kind of work on spec . and so i did call up the u\n",
      "tep back and maybe let a negotiation work . it 's my way or the highway . and \n",
      "h to back you up . staff and faculty work together on a day by day basis . far\n",
      "her person 's role , respect for the work that they do and contribution that t\n",
      "asically divorce the people from the work that 's being done . and so you beco\n",
      "r the people who are working and the work that they do , then you know , it 's\n",
      "staff , dumb broads doing dumb broad work . you could bring in anybody off the\n",
      "in anybody off the street and office work could be done . and that 's just rid\n",
      "as , oh , anybody could to a library work , is n't it just taking out a book a\n",
      "if the student has actually put some work into it , let them know that you 've\n",
      "o with honouring the other person 's work . has a lot to do with good manners \n",
      "es to define the field . like social work is one of them . and i think that th\n",
      "nnect that with being female and the work you did ? oh certainly . i understoo\n",
      "ay no . and it was n't even academic work . it had nothing to do with the acad\n",
      " had nothing to do with the academic work of the department . but it just happ\n"
     ]
    }
   ],
   "source": [
    "# now that we have a word frequency list, we can even use NLTK for concordance analysis (seeing word in context)\n",
    "# we can choose a word from the word frequency list, and search the original tokenized text for it after making it a Text object\n",
    "from nltk.text import Text\n",
    "\n",
    "text_list = Text(transcript_words)\n",
    "text_list.concordance(\"work\", lines=52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72299453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/iris_luc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/iris_luc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('know', 73),\n",
       " ('staff', 61),\n",
       " ('faculty', 60),\n",
       " ('think', 58),\n",
       " ('well', 52),\n",
       " ('work', 52),\n",
       " ('going', 47),\n",
       " ('yeah', 44),\n",
       " ('really', 41),\n",
       " ('like', 39)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is what our original Python script from the Python-I notebook now looks like with NLTK\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from string import punctuation\n",
    "punctuation = list(punctuation)\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "transcript = open('Bette-Smith-Transcript.txt', encoding=\"utf-8\").read().lower()\n",
    "\n",
    "transcript_words = word_tokenize(transcript)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([\"n't\", \"'s\", 'would'])\n",
    "\n",
    "filtered_transcript_words = []\n",
    "for word in transcript_words:\n",
    "    if word not in stop_words and word not in punctuation:\n",
    "        filtered_transcript_words.append(word)\n",
    "\n",
    "transcript_fdist = FreqDist(filtered_transcript_words)\n",
    "transcript_fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f12e43",
   "metadata": {},
   "source": [
    "## Practice Activity #5: Investigate your own text ðŸ”\n",
    "For this activity, use a `.txt` file you have on hand, or download a plain text file from [Project Gutenburg](https://www.gutenberg.org/). Place it in the same folder as this notebook, then open it in your code and see if you can use the NLTK to perform a frequency distribution or concordance analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "178de1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/iris_luc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/iris_luc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('whale', 1073),\n",
       " ('one', 900),\n",
       " ('like', 576),\n",
       " ('upon', 567),\n",
       " ('ahab', 494),\n",
       " ('man', 483),\n",
       " ('ship', 460),\n",
       " ('ye', 456),\n",
       " ('old', 443),\n",
       " ('sea', 375)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization is the process of splitting strings into their individual \"tokens\"\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words_en= stopwords.words('english')\n",
    "stop_words_es= stopwords.words('spanish')\n",
    "\n",
    "all_stop_words = stop_words_es + stop_words_en\n",
    "\n",
    "all_stop_words\n",
    "\n",
    "# Here is what our original Python script from the Python-I notebook now looks like with NLTK\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from string import punctuation\n",
    "punctuation = list(punctuation)\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "transcript = open('moby-dick.txt', encoding=\"utf-8\").read().lower()\n",
    "\n",
    "transcript_words = word_tokenize(transcript)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend([\"n't\", \"'s\", 'would', \"â€™\", \"â€œ\", \"â€\"])\n",
    "\n",
    "filtered_transcript_words = []\n",
    "for word in transcript_words:\n",
    "    if word not in stop_words and word not in punctuation:\n",
    "        filtered_transcript_words.append(word)\n",
    "\n",
    "transcript_fdist = FreqDist(filtered_transcript_words)\n",
    "transcript_fdist.most_common(10)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66ae0b5d",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/docs/) is a data analysis and manipulation tool, working with data in the form of a `dataframe`. A `dataframe` is a Python version of a spreadsheet!\n",
    "\n",
    "Like a spreadsheet, each column can be of a different type, and using Pandas means we can quickly perform a number of operations on our `dataframe` to prepare our data for use in analysis. To demonstrate functionality, we will be using an exported list of individuals accused of witchcraft in Scotland, from the [Survey of Scottish Witchcraft](https://www.shca.ed.ac.uk/Research/witches/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# we can add these arguments to set how many columns and rows we want Jupyter Notebook to display\n",
    "pd.options.display.max_columns = 70\n",
    "pd.options.display.max_rows = 70\n",
    "\n",
    "# we can import a CSV file very simply using Pandas's built in function\n",
    "witches_df = pd.read_csv(\"wdb_accused.csv\",  delimiter=\",\") \n",
    "witches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wow! that's a lot of confusing data!\n",
    "\n",
    "# to get the contents of only one column you can call the column by name\n",
    "print(witches_df['res_county'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can treat individual columns like lists by assigning them to a variable\n",
    "# witches_residence = witches_df['res_county']\n",
    "# print(type(witches_residence))\n",
    "\n",
    "# ...but this is still a pandas series, so to make a column into a list \"officially\" to avoid surprise errors, you can cast the column to be a list\n",
    "witches_residence = list(witches_df['res_county'])\n",
    "print(type(witches_residence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b6c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's a lot of columns, so let's reshape our dataframe to only have a few we're interested in\n",
    "witches_df = witches_df[['firstname', 'lastname', 'sex', 'age', 'res_county', 'maritalstatus', 'socioecstatus', 'occupation', 'notes']].copy()\n",
    "witches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# much better! now we can change a column name to make naming clearer\n",
    "witches_df = witches_df.rename(columns={\"res_county\": \"residing_county\"})\n",
    "witches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc2365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say we want to look at the occupation of each accused witch\n",
    "# there are a lot of NaN (Not a Number aka blank cells) which we can filter out using Pandas's .loc() and .notna() functions\n",
    "witches_df.loc[witches_df[\"occupation\"].notna()]\n",
    "\n",
    "# NOTE: there is also a function .isna() that does the opposite of .notna()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202db70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if I want to look only at those who were midwives, I can use .loc() with a comparison operator\n",
    "witches_df.loc[witches_df[\"occupation\"] == \"Midwife\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c8365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like FreqDist in NLTK, Pandas has .value_counts() which will tally up the occurances of unique values in a given row\n",
    "# so let's check the distribution of occupations\n",
    "witches_df[\"occupation\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea04f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want all basic statistics for numerical columns we can use .describe()\n",
    "# I'm interested to see the mean age of the accused\n",
    "witches_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to replace all instances of NaN in the dataframe with something more meaningful we can use the .fillna() function\n",
    "witches_df = witches_df.fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "witches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6287404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and take note that you can apply string methods to any column! \n",
    "# let's make everything in the \"notes\" column lowercase so it's normalised in case you need it for text analysis later\n",
    "witches_df[\"notes\"] = witches_df[\"notes\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b7b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "witches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "historian_notes = list(witches_df['notes'])\n",
    "\n",
    "all_notes = \"\"\n",
    "\n",
    "for note in historian_notes:\n",
    "    if note != 'unknown':\n",
    "        all_notes += note + '\\n '\n",
    "\n",
    "print(type(all_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, Pandas makes it really easy to export your dataframe as a CSV for publication or later use\n",
    "witches_df.to_csv(\"accused_cleaned.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae429064",
   "metadata": {},
   "source": [
    "# Putting Everything Together\n",
    "\n",
    "To begin this activity, first download your own CSV from the library as per Martha's instruction.\n",
    "\n",
    "Now, from this CSV of journal articles and abstracts, we would like you to perform a frequency distribution analysis on the column that lists all of the article abstracts so we can identify common words/topics currently being discussed in digital humanities research. \n",
    "\n",
    "To do this, you must use `pandas` to manipulate your desired column into a format (hint: str) that can be used for analysis with NLTK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62fd961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write activity code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f6f7357",
   "metadata": {},
   "source": [
    "# Identifying and Solving Errors\n",
    "\n",
    "Try and correct the following errors! For more of a challenge, try and identify the errors before running the code ðŸ”Ž"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0599db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 1\n",
    "\n",
    "people = [\n",
    "    {'name': 'Jolene', 'birth_year': 1955, 'death_year': 1972},\n",
    "    {'name': 'George', 'birth_year': 1942, 'death_year': 2010},\n",
    "    {'name': 'Charlene', 'birth_year': 1927, 'death_year': 1941},\n",
    "    {'name': 'David', 'birth_year': 1830, 'death_year': 1923},\n",
    "    {'name': 'Eve', 'birth_year': 1899, 'death_year': 1940},\n",
    "]\n",
    "\n",
    "print(people[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2f5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 2\n",
    "\n",
    "# takes two arguments and returns their sum\n",
    "def add_numbers(x, y):\n",
    "    return x + y\n",
    "\n",
    "result = add_numbers(5, 10)\n",
    "\n",
    "print(\"The sum of the numbers is:\", result)\n",
    "print(\"The difference of the numbers is:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef711cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 3\n",
    "\n",
    "year = 1955\n",
    "name = \"Jolene Barrie\"\n",
    "\n",
    "result = name + \" was born in \" + year\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd78af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 4\n",
    "\n",
    "people = [\n",
    "    {'name': 'Jolene', 'birth_year': 1955, 'death_year': 1972},\n",
    "    {'name': 'George', 'birth_year': 1942, 'death_year': 2010},\n",
    "    {'name': 'Charlene', 'birth_year': 1927, 'death_year': 1941},\n",
    "    {'name': 'David', 'birth_year': 1830, 'death_year' 1923},\n",
    "    {'name': 'Eve', 'birth_year': 1899, 'death_year': 1940},\n",
    "]\n",
    "\n",
    "for person in people:\n",
    "    print(\"Age at death: \" + str(person['death_year'] - person['birth_year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 5\n",
    "\n",
    "# convert strings to int\n",
    "def convert_to_num(year):\n",
    "    return int(year)\n",
    "\n",
    "year = \"1955\"\n",
    "name = \"Jolene Barrie\"\n",
    "\n",
    "convert_to_num(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
